{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e2e5a5",
   "metadata": {},
   "source": [
    "# Lets import the necessary library packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53aa2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as beauty\n",
    "import requests\n",
    "import datetime\n",
    "import csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee3a6be",
   "metadata": {},
   "source": [
    "Lets Connect to Jumia deals Website and pull in data using url as a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b36c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://deals.jumia.co.ke/catalog'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63fca9d",
   "metadata": {},
   "source": [
    "Now that Jumia has lots of items(posted products) split into over 1000 pages, i have created 'all_urls' veriable to scrap data from each and every page. I will loop from the first 160 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "788c8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls = []\n",
    "for page in range(160):\n",
    "    next_urls = url + '?page=' + str(page)\n",
    "    all_urls.append(next_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb2ccd",
   "metadata": {},
   "source": [
    "Now let's loop through our URLs and use get() from the requests library to create a connection and read the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1302711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in all_urls:\n",
    "    render = requests.get(url)\n",
    "    \n",
    "    soup = beauty(render.content, 'html.parser')\n",
    "    scrape = soup.find_all(class_=\"text-area\")\n",
    "    \n",
    "    scraped_data = []\n",
    "    for data in scrape:\n",
    "        scraped_data.append(data.get_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597fca7f",
   "metadata": {},
   "source": [
    "# Data Manipulation and Cleaning\n",
    "The dataframe is not in the format we want. To clean it up, will use split, replace and strip methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e84128",
   "metadata": {},
   "source": [
    "Now lets clean the scarp data by removing spaces, lines, Double quotes, Single quotes and brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "   scraped_data2 = [data.replace('\\n', '') for data in scraped_data]\n",
    "    scraped_data3 = [data.replace('   ', '') for data in scraped_data2]\n",
    "    scraped_data4 = [data.replace('\"','') for data in scraped_data3]\n",
    "    scraped_data5 = [data.replace(\"'\",'') for data in scraped_data4]\n",
    "    scraped_data6 = [data.replace(',', '') for data in scraped_data5]\n",
    "    \n",
    "    clean_scarp_data = str(scraped_data6)[1:-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8cd552",
   "metadata": {},
   "source": [
    "Now lets Create CSV and write headers and data into the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ca7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    header = ['PRODUCT/SERVICE','TYPE','LOCATION','PRICE','MONTH AND DAY','TIME']\n",
    "    data = [clean_scarp_data]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cffe018",
   "metadata": {},
   "source": [
    "#Now we are appending data to the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9230f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('All_jumia_deals_In_Kenya.csv', 'a', newline='', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        writer.writerow(header)\n",
    "\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb9b31e",
   "metadata": {},
   "source": [
    "now the whole code as one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d8712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as beauty\n",
    "import requests\n",
    "import datetime\n",
    "import csv \n",
    "\n",
    "url = 'https://deals.jumia.co.ke/catalog'\n",
    "\n",
    "\n",
    "\n",
    "all_urls = []\n",
    "for page in range(160):\n",
    "    next_urls = url + '?page=' + str(page)\n",
    "    all_urls.append(next_urls)\n",
    "   \n",
    "\n",
    " \n",
    "for url in all_urls:\n",
    "    render = requests.get(url)\n",
    "    \n",
    "    soup = beauty(render.content, 'html.parser')\n",
    "    scrape = soup.find_all(class_=\"text-area\")\n",
    "    \n",
    "    scraped_data = []\n",
    "\n",
    "    for data in scrape:\n",
    "        scraped_data.append(data.get_text())\n",
    "        \n",
    "    scraped_data2 = [data.replace('\\n', '') for data in scraped_data]\n",
    "    scraped_data3 = [data.replace('   ', '') for data in scraped_data2]\n",
    "    scraped_data4 = [data.replace('\"','') for data in scraped_data3]\n",
    "    scraped_data5 = [data.replace(\"'\",'') for data in scraped_data4]\n",
    "    scraped_data6 = [data.replace(',', '') for data in scraped_data5]\n",
    "    \n",
    "    clean_scarp_data = str(scraped_data6)[1:-1]\n",
    "\n",
    "    header = ['PRODUCT/SERVICE','TYPE','LOCATION','PRICE','MONTH AND DAY','TIME']\n",
    "    data = [clean_scarp_data]\n",
    "    with open('xxAll_jumia_deals_In_Kenya.csv', 'a', newline='', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "       \n",
    "        writer.writerow(header)\n",
    "        writer.writerow(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
